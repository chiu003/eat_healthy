# 步驟1: 解壓縮ZIP檔案並整理資料夾結構
def setup_data_directory():
    # 創建主數據目錄
    data_dir = 'bento_data'
    if os.path.exists(data_dir):
        shutil.rmtree(data_dir)
    os.makedirs(data_dir)

    # 創建訓練數據目錄和驗證數據目錄
    train_dir = os.path.join(data_dir, 'train')
    val_dir = os.path.join(data_dir, 'val')
    os.makedirs(train_dir)
    os.makedirs(val_dir)

    # 解壓縮並整理檔案
    zip_files = {
        r'/content/chicken.zip': '雞腿便當',
        r'/content/pork.zip': '排骨便當',
        r'/content/red_rice.zip': '紅糟肉便當',
        r'/content/onlypork.zip': '排骨',
        r'/content/onlyred.zip': '紅糟肉',
        r'/content/onlychicken.zip': '雞腿'
    }

    for zip_file, class_name in zip_files.items():
        if not os.path.exists(zip_file):
            print(f"警告: 找不到 {zip_file}")
            continue

        # 在訓練目錄下創建類別目錄
        class_train_dir = os.path.join(train_dir, class_name)
        class_val_dir = os.path.join(val_dir, class_name)
        os.makedirs(class_train_dir)
        os.makedirs(class_val_dir)

        # 解壓縮檔案到對應目錄
        try:
            with zipfile.ZipFile(zip_file, 'r') as zip_ref:
                # 獲取 ZIP 檔案中的所有檔案
                files = zip_ref.namelist()
                random.shuffle(files)  # 隨機打亂文件順序
                train_files = files[:int(0.8 * len(files))]  # 80% 用於訓練
                val_files = files[int(0.8 * len(files)):]    # 20% 用於驗證

                # 解壓縮訓練集檔案
                for file in train_files:
                    zip_ref.extract(file, class_train_dir)
                # 解壓縮驗證集檔案
                for file in val_files:
                    zip_ref.extract(file, class_val_dir)
        except zipfile.BadZipFile:
            print(f"錯誤: {zip_file} 不是有效的ZIP檔案")
            continue

    return train_dir, val_dir

# 步驟2: 調整圖片大小
def resize_images(directory):
    for root, _, files in os.walk(directory):
        for filename in files:
            if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.webp')):
                image_path = os.path.join(root, filename)
                try:
                    with Image.open(image_path) as img:
                        # 調整圖片大小為 150x300
                        resized_img = img.resize((150, 300))
                        resized_img.save(image_path)
                except Exception as e:
                    print(f"處理圖片 {filename} 時發生錯誤: {str(e)}")

# 自定義數據集類別
class BentoDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.classes = sorted(os.listdir(root_dir))
        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}

        self.images = []
        for cls in self.classes:
            class_path = os.path.join(root_dir, cls)
            if not os.path.isdir(class_path):
                continue
            for filename in os.listdir(class_path):
                if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.webp')):
                    self.images.append((os.path.join(class_path, filename), self.class_to_idx[cls]))

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_path, label = self.images[idx]
        image = Image.open(img_path).convert('RGB')

        if self.transform:
            image = self.transform(image)

        return image, label

# 步驟3: 建立深度學習模型
class BentoClassifier(nn.Module):
    def __init__(self, num_classes):
        super(BentoClassifier, self).__init__()
        self.resnet = models.resnet18(pretrained=True)
        self.resnet.fc = nn.Linear(512, num_classes)

    def forward(self, x):
        return self.resnet(x)

# 修改訓練過程
def validate_model(val_dir, model, transform, device):
    model.eval()
    val_dataset = BentoDataset(root_dir=val_dir, transform=transform)
    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)

    correct = 0
    total = 0
    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    accuracy = 100 * correct / total
    print(f"驗證集準確率: {accuracy:.2f}%")
    return accuracy

def train_model(train_dir, val_dir):
    # 設定 device 變數，選擇 GPU 或 CPU
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"使用的計算設備: {device}")

    # 確認是否有訓練數據
    if not os.path.exists(train_dir):
        raise FileNotFoundError(f"找不到訓練數據目錄: {train_dir}")

    # 設定數據轉換
    transform = transforms.Compose([
        transforms.Resize((150, 300)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225])
    ])

    # 載入訓練集
    train_dataset = BentoDataset(root_dir=train_dir, transform=transform)
    train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)

    # 初始化模型
    num_classes = len(train_dataset.classes)
    model = BentoClassifier(num_classes)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.0001)

    # 訓練模型
    model.to(device)
    train_losses = []
    val_accuracies = []
    num_epochs = 20
    best_val_accuracy = 0
    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        epoch_loss = 0.0
        for i, (inputs, labels) in enumerate(train_loader):
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
            epoch_loss += loss.item()
            if i % 5 == 4:  # 每5個批次打印一次
                print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 5:.3f}')
                running_loss = 0.0

        avg_epoch_loss = epoch_loss / len(train_loader)
        train_losses.append(avg_epoch_loss)  # 記錄該 epoch 的 loss

        # 每個 Epoch 訓練後進行驗證
        val_accuracy = validate_model(val_dir, model, transform, device)
        val_accuracies.append(val_accuracy)  # 記錄該 epoch 的 validation accuracy

        # 如果驗證準確率更好，則保存模型
        if val_accuracy > best_val_accuracy:
            best_val_accuracy = val_accuracy
            torch.save({
                'model_state_dict': model.state_dict(),
                'classes': train_dataset.classes
            }, 'best_bento_classifier.pth')

    return model, transform, train_dataset.classes, device, train_losses, val_accuracies
